{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Preamble\n",
    "\n",
    "### Set path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import ratelim\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "PROJECT_PATH = project_dir\n",
    "#NESTA_PATH = f'{os.environ[\"HOME\"]}/Nesta/nesta'\n",
    "#SQL_CONF_PATH = f'{os.environ[\"HOME\"]}/Nesta-AWS/AWS-RDS-config/innovation-mapping-5712.config'\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "sql_config = os.getenv('config_path')\n",
    "AWS_SUBSCRIPTION_KEY = '2559426f69474083a9362272bcd484fa'\n",
    "\n",
    "#sys.path += [PROJECT_PATH, NESTA_PATH]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%autoreload 2\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "import itertools\n",
    "from collections import Counter, defaultdict\n",
    "from cord19.transformers.utils import get_engine\n",
    "from cord19.transformers.utils import contains_keyword  # Specifies keywords ('SARS-CoV-2', 'COVID-19', 'coronavirus')\n",
    "from nesta.packages.mag.query_mag_api import build_expr\n",
    "from nesta.packages.mag.query_mag_api import query_mag_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "con = get_engine(sql_config)\n",
    "columns = ['id', 'created', 'title', 'abstract', 'mag_id', 'citation_count', 'article_source']\n",
    "chunks = pd.read_sql_table('arxiv_articles', con, columns=columns, chunksize=1000)\n",
    "covid_df = [df.loc[df.abstract.apply(contains_keyword) | df.title.apply(contains_keyword)]\n",
    "            for df in chunks]\n",
    "covid_df = pd.concat(covid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.to_csv(f\"{project_dir}/data/processed/covid_df.csv\",index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get MAG IDs for \"covid+AI\" articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(covid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_paper_ids = set(pd.read_csv(f\"{project_dir}/data/raw/ai_research/ai_paper_ids.csv\")['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#condition = covid_df.id.apply(lambda id: id in ai_paper_ids)\n",
    "#mag_ids = [int(id) for id in covid_df.mag_id.loc[condition] if not pd.isnull(id)]\n",
    "\n",
    "mag_ids = [int(id) for id in covid_df.mag_id if not pd.isnull(id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Get citation info from available MAG IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the citation info\n",
    "result_cont = []\n",
    "for expr in build_expr(mag_ids, 'Id'):\n",
    "    \n",
    "    result = query_mag_api(expr, fields=['Id', 'CitCon'], subscription_key=AWS_SUBSCRIPTION_KEY)\n",
    "    \n",
    "    result_cont.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = list(itertools.chain(*[x['entities'] for x in result_cont]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of {citing article id --> [list of citation article ids]}\n",
    "citers = {int(article['Id']): list(article['CitCon'].keys()) \n",
    "          if 'CitCon' in article else [] for article in all_results}\n",
    "\n",
    "# Set of ids of all cited articles\n",
    "citee_ids = set(int(id) for id in itertools.chain.from_iterable(citers.values()))\n",
    "\n",
    "f\"Number of unique citees: {len(citee_ids)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full info for each citation\n",
    "results = []\n",
    "query_count = 1000\n",
    "for expr in build_expr(citee_ids.union(citers), 'Id'):\n",
    "    count, offset = query_count, 0\n",
    "    # Do until no results left\n",
    "    while count == query_count:\n",
    "        _result = query_mag_api(expr, fields=['Id', 'J.JN', 'D', 'DN', 'DOI', 'CC', 'F.FN'], \n",
    "                                subscription_key=AWS_SUBSCRIPTION_KEY, \n",
    "                                offset=offset, query_count=query_count)['entities']      \n",
    "        \n",
    "        count = len(_result)\n",
    "        offset += count\n",
    "        results += _result\n",
    "        \n",
    "# Data quality: check that we returned all of the citation IDs\n",
    "returned_ids = {r['Id'] for r in results}\n",
    "len(citee_ids - returned_ids), len(set(citers) - returned_ids)  # <-- these should be zero!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Save the citation information for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up for flattened variable names\n",
    "field_dictionary = {'CC': 'citations', \n",
    "                    'D': 'date',\n",
    "                    'DN': 'title',\n",
    "                    'F': lambda x: {'fields_of_study': [_x['FN'] for _x in x]},\n",
    "                    'Id': 'mag_id',\n",
    "                    'J': lambda x: {'journal_title': x['JN']}}\n",
    "\n",
    "# Mapping of all article ids (both citers and citees) --> flattened article data\n",
    "articles = {}\n",
    "for r in results:\n",
    "    article = {}\n",
    "    # Convert the field names from MAG to something legible\n",
    "    for mag_key, field in field_dictionary.items():\n",
    "        # Ignore this MAG field if the result doesn't have it!\n",
    "        if mag_key not in r:\n",
    "            continue\n",
    "        # If the mapping is str --> value\n",
    "        if type(field) is str:\n",
    "            article[field] = r[mag_key]\n",
    "        # Otherwise assume that the mapping is a lambda function\n",
    "        else:\n",
    "            article.update(field(r[mag_key]))\n",
    "    articles[r['Id']] = article\n",
    "\n",
    "# Mapping of all article ids (both citers and citees) --> flattened article data\n",
    "with open(f'{PROJECT_PATH}/data/processed/ai_research/ai_article_mag_info.json', 'w') as f:\n",
    "    f.write(json.dumps(articles))\n",
    "\n",
    "# Citer ids. Together with `articles` you've got everything you need\n",
    "with open(f'{PROJECT_PATH}/data/processed/ai_research/citation_lookup.json', 'w') as f:\n",
    "    f.write(json.dumps(citers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
