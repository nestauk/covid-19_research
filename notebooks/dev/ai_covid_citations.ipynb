{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Preamble\n",
    "\n",
    "### Set path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "PROJECT_PATH = '../../'\n",
    "NESTA_PATH = f'{os.environ[\"HOME\"]}/Nesta/nesta'\n",
    "SQL_CONF_PATH = f'{os.environ[\"HOME\"]}/Nesta-AWS/AWS-RDS-config/innovation-mapping-5712.config'\n",
    "AWS_SUBSCRIPTION_KEY = ''\n",
    "\n",
    "sys.path += [PROJECT_PATH, NESTA_PATH]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%autoreload 2\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "import itertools\n",
    "from collections import Counter, defaultdict\n",
    "from cord19.transformers.utils import get_engine\n",
    "from cord19.transformers.utils import contains_keyword  # Specifies keywords ('SARS-CoV-2', 'COVID-19', 'coronavirus')\n",
    "from nesta.packages.mag.query_mag_api import build_expr\n",
    "from nesta.packages.mag.query_mag_api import query_mag_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "con = get_engine(SQL_CONF_PATH)\n",
    "columns = ['id', 'created', 'title', 'abstract', 'mag_id', 'citation_count', 'article_source']\n",
    "chunks = pd.read_sql_table('arxiv_articles', con, columns=columns, chunksize=1000)\n",
    "covid_df = [df.loc[df.abstract.apply(contains_keyword) | df.title.apply(contains_keyword)]\n",
    "            for df in chunks]\n",
    "covid_df = pd.concat(covid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get MAG IDs for \"covid+AI\" articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{PROJECT_PATH}/data/raw/ai_paper_ids.json\") as f:\n",
    "    ai_paper_ids = json.load(f)\n",
    "condition = covid_df.id.apply(lambda id: id in ai_paper_ids)\n",
    "mag_ids = [int(id) for id in covid_df.mag_id.loc[condition] if not pd.isnull(id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total AI paper IDs\", len(ai_paper_ids))\n",
    "print(\"Subtotal with valid MAG IDs\", len(mag_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Get citation info from available MAG IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the citation info\n",
    "for expr in build_expr(mag_ids, 'Id'):\n",
    "    result = query_mag_api(expr, fields=['Id', 'CitCon'], subscription_key=AWS_SUBSCRIPTION_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of {citing article id --> [list of citation article ids]}\n",
    "citers = {int(article['Id']): list(article['CitCon'].keys()) \n",
    "          if 'CitCon' in article else [] for article in result['entities']}\n",
    "\n",
    "# Set of ids of all cited articles\n",
    "citee_ids = set(int(id) for id in itertools.chain.from_iterable(citers.values()))\n",
    "\n",
    "f\"Number of unique citees: {len(citee_ids)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full info for each citation\n",
    "results = []\n",
    "query_count = 1000\n",
    "for expr in build_expr(citee_ids.union(citers), 'Id'):\n",
    "    count, offset = query_count, 0\n",
    "    # Do until no results left\n",
    "    while count == query_count:\n",
    "        _result = query_mag_api(expr, fields=['Id', 'J.JN', 'D', 'DN', 'DOI', 'CC', 'F.FN'], \n",
    "                                subscription_key=AWS_SUBSCRIPTION_KEY, \n",
    "                                offset=offset, query_count=query_count)['entities']      \n",
    "        \n",
    "        count = len(_result)\n",
    "        offset += count\n",
    "        results += _result\n",
    "        \n",
    "# Data quality: check that we returned all of the citation IDs\n",
    "returned_ids = {r['Id'] for r in results}\n",
    "len(citee_ids - returned_ids), len(set(citers) - returned_ids)  # <-- these should be zero!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Save the citation information for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up for flattened variable names\n",
    "field_dictionary = {'CC': 'citations', \n",
    "                    'D': 'date',\n",
    "                    'DN': 'title',\n",
    "                    'F': lambda x: {'fields_of_study': [_x['FN'] for _x in x]},\n",
    "                    'Id': 'mag_id',\n",
    "                    'J': lambda x: {'journal_title': x['JN']}}\n",
    "\n",
    "# Mapping of all article ids (both citers and citees) --> flattened article data\n",
    "articles = {}\n",
    "for r in results:\n",
    "    article = {}\n",
    "    # Convert the field names from MAG to something legible\n",
    "    for mag_key, field in field_dictionary.items():\n",
    "        # Ignore this MAG field if the result doesn't have it!\n",
    "        if mag_key not in r:\n",
    "            continue\n",
    "        # If the mapping is str --> value\n",
    "        if type(field) is str:\n",
    "            article[field] = r[mag_key]\n",
    "        # Otherwise assume that the mapping is a lambda function\n",
    "        else:\n",
    "            article.update(field(r[mag_key]))\n",
    "    articles[r['Id']] = article\n",
    "\n",
    "# Mapping of all article ids (both citers and citees) --> flattened article data\n",
    "with open(f'{PROJECT_PATH}/data/processed/ai_article_mag_info.json', 'w') as f:\n",
    "    f.write(json.dumps(articles))\n",
    "\n",
    "# Citer ids. Together with `articles` you've got everything you need\n",
    "with open(f'{PROJECT_PATH}/data/processed/citation_lookup.json', 'w') as f:\n",
    "    f.write(json.dumps(citers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Cross-tab FoS in articles and FoS of citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the fields of study for citers and citees\n",
    "fos_articles = []  # citers\n",
    "fos_citations = []  # citees\n",
    "for id, article in articles.items():\n",
    "    if id not in citers:\n",
    "        continue\n",
    "    _fos_articles = article['fields_of_study']  \n",
    "    # For citations, flatten the list\n",
    "    _fos_citations = list(itertools.chain.from_iterable(articles[int(c)][\"fields_of_study\"] for c in citers[id]))  \n",
    "    fos_articles += _fos_articles\n",
    "    fos_citations += _fos_citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 15 most common fields of study for plotting\n",
    "fa_most_common = [f for f, _ in Counter(fos_articles).most_common(15)]\n",
    "fc_most_common = [f for f, _ in Counter(fos_citations).most_common(15)]\n",
    "\n",
    "# Create a lookup of {citer FoS --> citee FoS --> count}\n",
    "# Note: this can be readily converted to DataFrame cross-tab\n",
    "cross_tab = defaultdict(lambda: defaultdict(int))\n",
    "for id, article in articles.items():\n",
    "    if id not in citers:\n",
    "        continue\n",
    "    # Get the fields of study\n",
    "    _fos_articles = [f for f in article['fields_of_study'] if f in fa_most_common]\n",
    "    # As before, for citations, flatten the list\n",
    "    _fos_citations = list(itertools.chain.from_iterable(articles[int(c)][\"fields_of_study\"] for c in citers[id]))\n",
    "    _fos_citations = [f for f in _fos_citations if f in fc_most_common]\n",
    "    # Increment the cross-tab\n",
    "    for fa in _fos_articles:\n",
    "        for fc in _fos_citations:\n",
    "            cross_tab[fa][fc] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise, sort and plot the cross-tab\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "_cross_tab = pd.DataFrame(cross_tab, columns=fa_most_common, index=fc_most_common).T\n",
    "_cross_tab_sum = _cross_tab.sum(axis=1) \n",
    "cross_tab_norm = _cross_tab.apply(lambda row: row/_cross_tab_sum, axis=0)\n",
    "sorted_columns = cross_tab_norm.sum().sort_values(ascending=False).index\n",
    "cross_tab_norm = cross_tab_norm[sorted_columns]\n",
    "sns.heatmap(pd.DataFrame(cross_tab_norm), ax=ax)\n",
    "ax.set_ylabel(\"Articles by field of study\")\n",
    "ax.set_xlabel(\"Citations by field of study\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
